{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a2a4b3-8c1e-4433-aef9-5e3bbd6b0179",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install transformers>=4.46.0\n",
    "!pip install datasets\n",
    "!pip install unsloth[colab-new]@git+https://github.com/unslothai/unsloth.git\n",
    "!pip install xformers --no-cache-dir   --index-url https://download.pytorch.org/whl/cu124\n",
    "!pip install flash-attn --no-build-isolation --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c268d6f8-7757-49d0-be33-8047b84bc1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "HF_TOKEN = \"your_key\"\n",
    "login(HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e0314b-6a69-44e4-8421-5c25163cded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/\n",
    "from huggingface_hub import snapshot_download, hf_hub_download\n",
    "from datasets import Dataset\n",
    "\n",
    "REXVQA_REPO = \"rajpurkarlab/ReXVQA\"\n",
    "REXGRAD_REPO = \"rajpurkarlab/ReXGradient-160K\"\n",
    "\n",
    "\n",
    "meta_path = snapshot_download(repo_id=REXGRAD_REPO, repo_type=\"dataset\")\n",
    "\n",
    "!cat {meta_path}/deid_png.part* > /home/deid_png.tar\n",
    "!tar -xf /home/deid_png.tar\n",
    "meta_path = snapshot_download(repo_id=REXVQA_REPO, repo_type=\"dataset\")\n",
    "!mkdir /home/QA_json/\n",
    "!cp  {meta_path}/metadata/test_vqa_data.json  /home/QA_json/\n",
    "!cp  {meta_path}/metadata/train_vqa_data.json  /home/QA_json/\n",
    "!cp  {meta_path}/metadata/valid_vqa_data.json  /home/QA_json/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c56612b-860c-4330-a0ab-912be93a9589",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, json, random\n",
    "from typing import Dict, List, Iterable, Union, Optional\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from datasets import IterableDataset\n",
    "\n",
    "def load_items_once(json_path: str) -> List[Dict]:\n",
    "    \"\"\"Load and normalize one time; return a list of records (dicts).\"\"\"\n",
    "    with open(json_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    items = list(data.values()) if isinstance(data, dict) else list(data)\n",
    "    return items\n",
    "# =======================\n",
    "# Config / Constants\n",
    "# =======================\n",
    "_OPTION_LETTERS = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"]\n",
    "\n",
    "REASONING_START = \"<start_working_out>\"\n",
    "REASONING_END   = \"<end_working_out>\"\n",
    "SOLUTION_START  = \"<SOLUTION>\"\n",
    "SOLUTION_END    = \"</SOLUTION>\"\n",
    "\n",
    "# Probability of adding demographics/context and body/view into the prompt per split.\n",
    "# For TEST we always add them (1.0 as requested).\n",
    "PROMPT_META_PROB = {\n",
    "    \"train\": 0.05,   # \"very few\"\n",
    "    \"val\":   0.05,\n",
    "    \"test\":  1.0,    # ALWAYS on test split\n",
    "}\n",
    "PROMPT_BODYVIEW_PROB = {\n",
    "    \"train\": 0.30,   # sometimes\n",
    "    \"val\":   0.30,\n",
    "    \"test\":  1.0,    # ALWAYS on test split\n",
    "}\n",
    "\n",
    "MODEL_ID = \"unsloth/medgemma-4b-it\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "TRAIN_JSON = \"/home/QA_json/train_vqa_data.json\"\n",
    "VAL_JSON   = \"/home/QA_json/valid_vqa_data.json\"\n",
    "TEST_JSON  = \"/home/QA_json/test_vqa_data.json\"\n",
    "\n",
    "# Load once per split\n",
    "train_items = load_items_once(TRAIN_JSON)\n",
    "val_items   = load_items_once(VAL_JSON)\n",
    "test_items  = load_items_once(TEST_JSON)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8543c41-bd8d-4e29-bfd4-04f99d82d5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, json, random\n",
    "from typing import Dict, List, Iterable, Union, Optional\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from datasets import IterableDataset\n",
    "\n",
    "\n",
    "# =======================\n",
    "# Small helpers\n",
    "# =======================\n",
    "def _norm(s: Optional[str]) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", (s or \"\")).strip()\n",
    "\n",
    "def _format_options(options: List[str]) -> str:\n",
    "    lines = []\n",
    "    for i, opt in enumerate(options):\n",
    "        letter = _OPTION_LETTERS[i] if i < len(_OPTION_LETTERS) else chr(ord(\"A\") + i)\n",
    "        opt = _norm(opt)\n",
    "        if re.match(r\"^[A-F][\\)\\.\\-:]\\s\", opt, flags=re.IGNORECASE):\n",
    "            lines.append(opt)  # already labeled\n",
    "        else:\n",
    "            lines.append(f\"{letter}) {opt}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def _safe_open_as_rgb(img_path: str) -> Optional[Image.Image]:\n",
    "    \"\"\"Open image robustly; fix bit-depth; return RGB PIL.Image or None on failure.\"\"\"\n",
    "    try:\n",
    "        im = Image.open(img_path)\n",
    "        im.load()  # force read\n",
    "        arr = np.array(im)\n",
    "\n",
    "        # 16-bit -> keep high 8 bits\n",
    "        if arr.dtype == np.uint16:\n",
    "            arr8 = (arr >> 8).astype(np.uint8)\n",
    "            im = Image.fromarray(arr8)\n",
    "        elif im.mode == \"I\":  # 32-bit signed int -> min-max normalize to 0..255\n",
    "            arr = arr.astype(np.int32)\n",
    "            mn, mx = int(arr.min()), int(arr.max())\n",
    "            if mx > mn:\n",
    "                scale = 255.0 / (mx - mn)\n",
    "                arr8 = ((arr - mn) * scale).astype(np.uint8)\n",
    "            else:\n",
    "                arr8 = np.zeros_like(arr, dtype=np.uint8)\n",
    "            im = Image.fromarray(arr8, mode=\"L\")\n",
    "        return im.convert(\"RGB\")\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# =======================\n",
    "# Reasoning & Prompt builders\n",
    "# =======================\n",
    "def _build_reasoning(record: Dict) -> str:\n",
    "    \"\"\"\n",
    "    Your latest choice: reasoning contains ONLY (in order)\n",
    "    - Findings:\n",
    "    - Impression:\n",
    "    (No correct_answer_explanation and never the answer here.)\n",
    "    \"\"\"\n",
    "    findings = _norm(record.get(\"Findings\"))\n",
    "    impression = _norm(record.get(\"Impression\"))\n",
    "\n",
    "    parts = []\n",
    "    if findings:\n",
    "        parts.append(f\"Findings: {findings}\")\n",
    "    if impression:\n",
    "        parts.append(f\"Impression: {impression}\")\n",
    "    return \"\\n\".join(parts).strip()\n",
    "\n",
    "def _maybe_meta_block(record: Dict, prob: float) -> str:\n",
    "    \"\"\"Demographics/context block with probability `prob` (always for test).\"\"\"\n",
    "    if random.random() >= prob:\n",
    "        return \"\"\n",
    "    patient_sex  = record.get(\"PatientSex\")\n",
    "    patient_age  = record.get(\"PatientAge\")\n",
    "    ethnic_group = record.get(\"EthnicGroup\")\n",
    "    weight       = record.get(\"PatientWeight\")\n",
    "    size         = record.get(\"PatientSize\")\n",
    "    indication   = record.get(\"Indication\")\n",
    "    comparison   = record.get(\"Comparison\")\n",
    "\n",
    "    lines = []\n",
    "    if patient_sex: lines.append(f\"PatientSex: {patient_sex}\")\n",
    "    if patient_age: lines.append(f\"PatientAge: {patient_age}\")\n",
    "    if ethnic_group: lines.append(f\"EthnicGroup: {ethnic_group}\")\n",
    "    try:\n",
    "        if weight is not None and weight == weight:\n",
    "            lines.append(f\"PatientWeight: {weight}\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        if size is not None and size == size:\n",
    "            lines.append(f\"PatientSize: {size}\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    if indication: lines.append(f\"Indication: {indication}\")\n",
    "    if comparison: lines.append(f\"Comparison: {comparison}\")\n",
    "\n",
    "    return (\"CONTEXT:\\n\" + \"\\n\".join(lines)) if lines else \"\"\n",
    "\n",
    "def _maybe_body_view_block(body_part_sel, view_sel, prob: float) -> str:\n",
    "    \"\"\"Randomly include ImageBodyPart & ImageViewPosition (always on test).\"\"\"\n",
    "    if random.random() >= prob:\n",
    "        return \"\"\n",
    "    lines = []\n",
    "    if body_part_sel:\n",
    "        if isinstance(body_part_sel, list):\n",
    "            lines.append(f\"ImageBodyPart: {', '.join(body_part_sel)}\")\n",
    "        else:\n",
    "            lines.append(f\"ImageBodyPart: {body_part_sel}\")\n",
    "    if view_sel:\n",
    "        if isinstance(view_sel, list):\n",
    "            lines.append(f\"ImageViewPosition: {', '.join(view_sel)}\")\n",
    "        else:\n",
    "            lines.append(f\"ImageViewPosition: {view_sel}\")\n",
    "    return \"\\n\".join(lines) if lines else \"\"\n",
    "\n",
    "def _test_only_block(record: Dict, split: str) -> str:\n",
    "    if split != \"test\":\n",
    "        return \"\"\n",
    "    cat_ = record.get(\"category\")\n",
    "    cls_ = record.get(\"class\")\n",
    "    lines = []\n",
    "    if cat_:\n",
    "        lines.append(f\"Category: {cat_}\")\n",
    "    if cls_:\n",
    "        lines.append(f\"Class: {cls_}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def _build_instruction(\n",
    "    record: Dict,\n",
    "    split: str,\n",
    "    body_part_sel,\n",
    "    view_sel,\n",
    ") -> str:\n",
    "    question     = _norm(record.get(\"question\"))\n",
    "    options      = record.get(\"options\") or []\n",
    "    options_block = _format_options(options) if options else \"\"\n",
    "\n",
    "    meta_prob     = PROMPT_META_PROB.get(split, 0.0)\n",
    "    bodyview_prob = PROMPT_BODYVIEW_PROB.get(split, 0.0)\n",
    "\n",
    "    meta_block      = _maybe_meta_block(record, meta_prob)\n",
    "    body_view_block = _maybe_body_view_block(body_part_sel, view_sel, bodyview_prob)\n",
    "    test_block      = _test_only_block(record, split)\n",
    "\n",
    "    chunks = []\n",
    "    if test_block:\n",
    "        chunks.append(test_block)\n",
    "    if question:\n",
    "        chunks.append(question)\n",
    "    if options_block:\n",
    "        chunks.append(\"OPTIONS:\\n\" + options_block)\n",
    "    if meta_block:\n",
    "        chunks.append(meta_block)\n",
    "    if body_view_block:\n",
    "        chunks.append(body_view_block)\n",
    "\n",
    "    return \"\\n\\n\".join([c for c in chunks if c]).strip()\n",
    "\n",
    "# =======================\n",
    "# Image + metadata selection (synced)\n",
    "# =======================\n",
    "def _select_image_and_meta(item: Dict) -> (Optional[str], Optional[Union[str, List[str]]], Optional[Union[str, List[str]]]):\n",
    "    \"\"\"\n",
    "    Choose one image path. If ImagePath, ImageBodyPart, ImageViewPosition are lists,\n",
    "    pick a single random index and return matched body/view for the same index.\n",
    "    Maps '../' -> '/home/'.\n",
    "    \"\"\"\n",
    "    raw_image_paths = item.get(\"ImagePath\")\n",
    "    body_parts_list = item.get(\"ImageBodyPart\")\n",
    "    views_list      = item.get(\"ImageViewPosition\")\n",
    "\n",
    "    body_part_sel = None\n",
    "    view_sel      = None\n",
    "\n",
    "    if isinstance(raw_image_paths, list) and raw_image_paths:\n",
    "        idx = random.randrange(len(raw_image_paths))\n",
    "        raw_image_path = raw_image_paths[idx]\n",
    "        if isinstance(body_parts_list, list) and len(body_parts_list) == len(raw_image_paths):\n",
    "            body_part_sel = body_parts_list[idx]\n",
    "        else:\n",
    "            body_part_sel = body_parts_list\n",
    "        if isinstance(views_list, list) and len(views_list) == len(raw_image_paths):\n",
    "            view_sel = views_list[idx]\n",
    "        else:\n",
    "            view_sel = views_list\n",
    "    else:\n",
    "        raw_image_path = raw_image_paths\n",
    "        body_part_sel  = body_parts_list\n",
    "        view_sel       = views_list\n",
    "\n",
    "    if not isinstance(raw_image_path, str) or not raw_image_path:\n",
    "        return None, body_part_sel, view_sel\n",
    "\n",
    "    img_path = raw_image_path.replace(\"../\", \"/home/\")\n",
    "    return img_path, body_part_sel, view_sel\n",
    "\n",
    "# =======================\n",
    "# Dataset factory\n",
    "# =======================\n",
    "def create_iterable_dataset_from_items(\n",
    "    items: List[Dict],\n",
    "    split: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    Build an IterableDataset from preloaded items.\n",
    "    - No JSON re-read per iteration.\n",
    "    - Reasoning: Findings -> Impression (no answer here).\n",
    "    - Solution: ONLY 'correct_answer' (letter or text).\n",
    "    - Prompt:\n",
    "        * Train/Val: demographics & body/view appear with small probability.\n",
    "        * Test: ALWAYS include demographics & body/view + Category/Class lines.\n",
    "    - Yields a dict with {messages, split, category, class, correct_answer}.\n",
    "    \"\"\"\n",
    "    def generator() -> Iterable[Dict]:\n",
    "        processed = 0\n",
    "        for item in items:\n",
    "            # Pick image and synchronized body/view\n",
    "            img_path, body_part_sel, view_sel = _select_image_and_meta(item)\n",
    "            if not img_path or not os.path.exists(img_path):\n",
    "                continue\n",
    "\n",
    "            img = _safe_open_as_rgb(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "\n",
    "            instruction = _build_instruction(item, split, body_part_sel, view_sel)\n",
    "            reasoning   = _build_reasoning(item)\n",
    "\n",
    "            # Final answer: ONLY the letter/text in 'correct_answer'\n",
    "            correct_letter = _norm(item.get(\"answer\") or item.get(\"correct_answer\"))\n",
    "            explanation = _norm(\n",
    "                item.get(\"explanation\") or item.get(\"correct_answer_explanation\")\n",
    "            )\n",
    "            \n",
    "            if explanation:\n",
    "                # \"Correct answer: B) Minimal scarring at left base. Explanation: ...\"\n",
    "                correct_answer = f\"{correct_letter} - Explanation: {explanation}\"\n",
    "            else:\n",
    "                # If no explanation, just show the letter\n",
    "                correct_answer = correct_letter\n",
    "                \n",
    "            assistant_response = (\n",
    "                f\"{REASONING_START}\\n{reasoning}\\n{REASONING_END}\\n\\n\"\n",
    "                f\"{SOLUTION_START}\\n{correct_answer}\\n{SOLUTION_END}\"\n",
    "            )\n",
    "\n",
    "            processed += 1\n",
    "            if processed % 1000 == 0:\n",
    "                print(f\"[{split}] Processed {processed} samples...\")\n",
    "\n",
    "            output =  {\n",
    "                \"messages\": [\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\"type\": \"text\", \"text\": instruction},\n",
    "                            {\"type\": \"image\", \"image\": img},\n",
    "                        ],\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"assistant\",\n",
    "                        \"content\": [{\"type\": \"text\", \"text\": assistant_response}],\n",
    "                    },\n",
    "                ],\n",
    "                \"split\": split,\n",
    "                # Expose these always for a stable schema\n",
    "                \"category\": _norm(item.get(\"category\")),\n",
    "                \"class\": _norm(item.get(\"class\")),\n",
    "                \"correct_answer\": correct_answer,\n",
    "                \"image_path\": img_path,  # handy for debugging/audits\n",
    "            }\n",
    "            if split == \"test\":\n",
    "                yield output\n",
    "            else:\n",
    "                \n",
    "                yield output[\"messages\"]\n",
    "    return IterableDataset.from_generator(generator)\n",
    "\n",
    "# =======================\n",
    "# Example wiring\n",
    "# =======================\n",
    "# Assuming you already loaded JSON into lists:\n",
    "# train_items, val_items, test_items = ...\n",
    "\n",
    "train_dataset = create_iterable_dataset_from_items(train_items, split=\"train\")\n",
    "val_dataset   = create_iterable_dataset_from_items(val_items,   split=\"val\")\n",
    "test_dataset  = create_iterable_dataset_from_items(test_items,  split=\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8116fae-ec77-4237-bdb5-5ba3a97f2d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': [{'type': 'text', 'text': 'Which of the following findings is absent in the lung fields on this chest X-ray?\\n\\nOPTIONS:\\nA. Focal airspace disease\\nB. Mild peribronchial thickening\\nC. Cardiomegaly\\nD. Pleural effusion'}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=748x747 at 0x7F723A8908E0>}]}, {'role': 'assistant', 'content': [{'type': 'text', 'text': '<start_working_out>\\nFindings: The cardiomediastinal silhouette is unremarkable. Mild peribronchial thickening is noted. There is no evidence of focal airspace disease, pulmonary edema, suspicious pulmonary nodule/mass, pleural effusion, or pneumothorax. No acute bony abnormalities are identified.\\nImpression: Mild peribronchial thickening-likely chronic. No other significant abnormalities.\\n<end_working_out>\\n\\n<SOLUTION>\\nA - Explanation: The chest X-ray does not show any focal airspace disease, making A the correct answer. Mild peribronchial thickening is present, and there is no evidence of cardiomegaly or pleural effusion.\\n</SOLUTION>'}]}]\n"
     ]
    }
   ],
   "source": [
    "sample = next(iter(val_dataset))\n",
    "\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1830984-c791-46de-8764-e2586e251d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.8.5: Fast Gemma3 patching. Transformers: 4.55.2.\n",
      "   \\\\   /|    NVIDIA A40. Num GPUs = 1. Max memory: 44.352 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: Making `base_model.model.model.vision_tower.vision_model` require gradients\n",
      "Model loaded successfully with LoRA adapters\n"
     ]
    }
   ],
   "source": [
    "from unsloth.trainer import UnslothVisionDataCollator\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "import torch \n",
    "from unsloth import FastVisionModel \n",
    "from transformers import TextStreamer \n",
    "from trl import SFTTrainer \n",
    "from transformers import TrainingArguments \n",
    "from unsloth import is_bfloat16_supported \n",
    "\n",
    "model, processor = FastVisionModel.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    load_in_4bit = True, # Use 4bit to reduce memory use. False for 16bit LoRA.\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for long context\n",
    ")\n",
    "# Add LoRA adapters\n",
    "model = FastVisionModel.get_peft_model(\n",
    "    model,\n",
    "    finetune_vision_layers     = True, # False if not finetuning vision layers\n",
    "    finetune_language_layers   = True, # False if not finetuning language layers\n",
    "    finetune_attention_modules = True, # False if not finetuning attention layers\n",
    "    finetune_mlp_modules       = True, # False if not finetuning MLP layers\n",
    "\n",
    "    r = 64,                           # The larger, the higher the accuracy, but might overfit\n",
    "    lora_alpha = 64,                  # Recommended alpha == r at least\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,               # We support rank stabilized LoRA\n",
    "    loftq_config = None,               # And LoftQ\n",
    "    target_modules = \"all-linear\",    # Optional now! Can specify a list if needed\n",
    "    modules_to_save=[\n",
    "        \"lm_head\",\n",
    "        \"embed_tokens\",\n",
    "    ],\n",
    ")\n",
    "print(\"Model loaded successfully with LoRA adapters\")\n",
    "\n",
    "FastVisionModel.for_training(model) # Enable for training!\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    processing_class=processor.tokenizer,\n",
    "    data_collator=UnslothVisionDataCollator(model, processor),\n",
    "    args = SFTConfig(\n",
    "        per_device_train_batch_size = 4,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        gradient_checkpointing = True,\n",
    "\n",
    "        # use reentrant checkpointing\n",
    "        gradient_checkpointing_kwargs = {\"use_reentrant\": False},\n",
    "        max_grad_norm = 0.3,              # max gradient norm based on QLoRA paper\n",
    "        warmup_ratio = 0.03,\n",
    "        max_steps = 100,\n",
    "        #num_train_epochs = 2,          # Set this instead of max_steps for full training runs\n",
    "        learning_rate = 2e-4,\n",
    "        logging_steps = 1,\n",
    "        save_strategy=\"steps\",\n",
    "        optim = \"adamw_torch_fused\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"cosine\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"none\",             # For Weights and Biases\n",
    "\n",
    "        # You MUST put the below items for vision finetuning:\n",
    "        remove_unused_columns = False,\n",
    "        dataset_text_field = \"\",\n",
    "        dataset_kwargs = {\"skip_prepare_dataset\": True},\n",
    "        max_length = 2048,\n",
    "    )\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f846f89-abe3-4c0e-a121-290be8460659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting SFT training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 1,600 | Num Epochs = 9,223,372,036,854,775,807 | Total steps = 100\n",
      "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 4 x 1) = 16\n",
      " \"-____-\"     Trainable parameters = 153,991,168 of 4,454,070,640 (3.46% trained)\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 15:56, Epoch 1/9223372036854775807]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.932900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.006500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.645600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.254300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.757000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.572300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.429100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.198800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.375600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.138400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.874900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.861300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.791500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.729400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.604500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.803500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.677800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.646000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.662800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.698600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.587300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.632000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.703600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.671000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.508900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.552700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.657800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.514600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.505300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.879700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.727000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.682700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.013500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.776900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.758500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.039200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.807000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.845400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.719100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.545500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.617000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.724800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.554400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.678500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.566100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.558600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.399200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.488800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.806600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.779300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.733700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.623500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.518000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.543400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.613600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.686700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.896400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.518500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.533100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.592300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.826100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.705800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.745500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.509700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.445500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.948200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.534100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.541200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.954700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.825600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.613600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.721900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.950300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.452300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.878400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.600600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.471200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.580700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.381200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.626700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.416500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.569900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.666700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.822100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.849500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.661700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.783500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.860400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.717400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.548600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.659500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.981300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.806000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.781900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.710300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.739200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.640900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.589700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Processed 1000 samples...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Starting SFT training...\")\n",
    "trainer_stats = trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1958f29-54e8-4022-b722-0c4f656e3b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start_working_out>\n",
      "Findings: Cardiomegaly is noted. There is stable bibasilar scarring noted. The aorta remains calcified. Mediastinal contours appear stable. The patient status post CABG. Postoperative surgical clips are noted.\n",
      "Impression: No acute cardiopulmonary findings. Stable bibasilar scarring.\n",
      "<end_working_out>\n",
      "\n",
      "<SOLUTION>\n",
      "C - Explanation: The chest X-ray shows stable bibasilar scarring, indicating that the scarring is not worsening or resolving, but remains stable.\n",
      "</SOLUTION><end_of_turn>\n"
     ]
    }
   ],
   "source": [
    "FastVisionModel.for_inference(model)  # Enable for inference!\n",
    "\n",
    "data = next(iter(test_dataset))\n",
    "\n",
    "\n",
    "image = data[\"messages\"][0][\"content\"][1].pop(\"image\")\n",
    "messages = [data[\"messages\"][0]]\n",
    "class_data= data[\"class\"]\n",
    "correct_answer= data[\"correct_answer\"]\n",
    "\n",
    "\n",
    "input_text = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "inputs = processor(\n",
    "    image,\n",
    "    input_text,\n",
    "    add_special_tokens=False,\n",
    "    return_tensors=\"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "\n",
    "text_streamer = TextStreamer(processor.tokenizer, skip_prompt=True)\n",
    "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 512,\n",
    "                   use_cache=True, temperature = 1.0, top_p = 0.95, top_k = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a7cb6d-2e5c-4c60-bb36-535948023259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save locally to 16bit\n",
    "#model.save_pretrained_merged(\"/home/unsloth_finetune\", processor)\n",
    "# Save locally\n",
    "#model.save_pretrained(\"/home/weights\")\n",
    "#processor.save_pretrained(\"/home/weights\")\n",
    "\n",
    "\n",
    "# To export and save to your Hugging Face account\n",
    "model.push_to_hub_merged(\"SerdarHelli/medgemma-4b-it_rexvqa\", processor, token = HF_TOKEN)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
