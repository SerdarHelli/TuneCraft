{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8a2a4b3-8c1e-4433-aef9-5e3bbd6b0179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting datasets\n",
      "  Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.8/494.8 KB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting dill<0.3.9,>=0.3.0\n",
      "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 KB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.4)\n",
      "Collecting multiprocess<0.70.17\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 KB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.34.4)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m113.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (25.0)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 KB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec[http]<=2025.3.0,>=2023.1.0\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 KB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
      "Collecting pyarrow>=15.0.0\n",
      "  Downloading pyarrow-21.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (42.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.6)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.19.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
      "  Downloading aiohttp-3.12.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m143.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.7)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2025.6.15)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 KB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pytz>=2020.1\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 KB\u001b[0m \u001b[31m105.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting async-timeout<6.0,>=4.0\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.6.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (241 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.6/241.6 KB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiosignal>=1.4.0\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.7.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (222 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.9/222.9 KB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.17.0\n",
      "  Downloading yarl-1.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.1/326.1 KB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiohappyeyeballs>=2.5.0\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Collecting propcache>=0.2.0\n",
      "  Downloading propcache-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (198 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.3/198.3 KB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: pytz, xxhash, tzdata, pyarrow, propcache, multidict, fsspec, frozenlist, dill, async-timeout, aiohappyeyeballs, yarl, pandas, multiprocess, aiosignal, aiohttp, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.7.0\n",
      "    Uninstalling fsspec-2025.7.0:\n",
      "      Successfully uninstalled fsspec-2025.7.0\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 async-timeout-5.0.1 datasets-4.0.0 dill-0.3.8 frozenlist-1.7.0 fsspec-2025.3.0 multidict-6.6.4 multiprocess-0.70.16 pandas-2.3.1 propcache-0.3.2 pyarrow-21.0.0 pytz-2025.2 tzdata-2025.2 xxhash-3.5.0 yarl-1.20.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git\n",
      "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-z315g49o/unsloth_e77ce0e0a23648d8ab6f259d17303431\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-z315g49o/unsloth_e77ce0e0a23648d8ab6f259d17303431\n",
      "  Resolved https://github.com/unslothai/unsloth.git to commit dc26a7a0eb20c31549318396f53639ba8c01025e\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h\u001b[33m  WARNING: Generating metadata for package unsloth produced metadata for project name unknown. Fix your #egg=unsloth fragments.\u001b[0m\u001b[33m\n",
      "\u001b[0mDiscarding \u001b[4;34mgit+https://github.com/unslothai/unsloth.git\u001b[0m: \u001b[33mRequested unknown from git+https://github.com/unslothai/unsloth.git has inconsistent name: filename has 'unsloth', but metadata has 'unknown'\u001b[0m\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement unsloth (unavailable) (from versions: 2024.8, 2024.9, 2024.9.post1, 2024.9.post2, 2024.9.post3, 2024.9.post4, 2024.10.0, 2024.10.1, 2024.10.2, 2024.10.4, 2024.10.5, 2024.10.6, 2024.10.7, 2024.11.2, 2024.11.4, 2024.11.5, 2024.11.6, 2024.11.7, 2024.11.8, 2024.11.9, 2024.11.10, 2024.11.11, 2024.12.1, 2024.12.2, 2024.12.3, 2024.12.4, 2024.12.5, 2024.12.6, 2024.12.7, 2024.12.8, 2024.12.9, 2024.12.10, 2024.12.11, 2024.12.12, 2025.1.1, 2025.1.2, 2025.1.3, 2025.1.4, 2025.1.5, 2025.1.6, 2025.1.8, 2025.2.2, 2025.2.3, 2025.2.4, 2025.2.5, 2025.2.6, 2025.2.7, 2025.2.8, 2025.2.9, 2025.2.10, 2025.2.11, 2025.2.12, 2025.2.13, 2025.2.14, 2025.2.15, 2025.3.1, 2025.3.2, 2025.3.3, 2025.3.4, 2025.3.5, 2025.3.6, 2025.3.7, 2025.3.8, 2025.3.9, 2025.3.10, 2025.3.11, 2025.3.12, 2025.3.13, 2025.3.14, 2025.3.15, 2025.3.16, 2025.3.17, 2025.3.18, 2025.3.19, 2025.4.1, 2025.4.2, 2025.4.3, 2025.4.4, 2025.4.5, 2025.4.7, 2025.5.1, 2025.5.2, 2025.5.3, 2025.5.4, 2025.5.5, 2025.5.6, 2025.5.7, 2025.5.8, 2025.5.9, 2025.6.1, 2025.6.2, 2025.6.3, 2025.6.4, 2025.6.5, 2025.6.6, 2025.6.7, 2025.6.8, 2025.6.9, 2025.6.10, 2025.6.11, 2025.6.12, 2025.7.1, 2025.7.2, 2025.7.3, 2025.7.4, 2025.7.5, 2025.7.6, 2025.7.7, 2025.7.8, 2025.7.10, 2025.7.11, 2025.8.1, 2025.8.2, 2025.8.3, 2025.8.4, 2025.8.5, 2025.8.6)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for unsloth (unavailable)\u001b[0m\u001b[31m\n",
      "\u001b[0mLooking in indexes: https://download.pytorch.org/whl/cu124\n",
      "Collecting xformers\n",
      "  Downloading https://download.pytorch.org/whl/cu124/xformers-0.0.29.post3-cp310-cp310-manylinux_2_28_x86_64.whl (43.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 MB\u001b[0m \u001b[31m249.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch==2.6.0\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp310-cp310-linux_x86_64.whl (768.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m768.4/768.4 MB\u001b[0m \u001b[31m269.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers) (2.2.6)\n",
      "Collecting networkx\n",
      "  Downloading https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m314.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m265.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.4.127\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 KB\u001b[0m \u001b[31m312.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.4.127\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m266.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0->xformers) (3.1.6)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m257.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0->xformers) (3.19.1)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m270.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0->xformers) (4.14.0)\n",
      "Collecting nvidia-nccl-cu12==2.21.5\n",
      "  Downloading https://download.pytorch.org/whl/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m246.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m242.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m160.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.4.127\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 KB\u001b[0m \u001b[31m410.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting triton==3.2.0\n",
      "  Downloading https://download.pytorch.org/whl/triton-3.2.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (166.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.6/166.6 MB\u001b[0m \u001b[31m230.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.1.170\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m249.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m256.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting sympy==1.13.1\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m274.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0->xformers) (2025.3.0)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m256.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvjitlink-cu12==12.4.127\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m248.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting mpmath<1.4,>=1.1.0\n",
      "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 KB\u001b[0m \u001b[31m311.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.6.0->xformers) (3.0.2)\n",
      "Installing collected packages: triton, nvidia-cusparselt-cu12, mpmath, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, xformers\n",
      "Successfully installed mpmath-1.3.0 networkx-3.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.6.0+cu124 triton-3.2.0 xformers-0.0.29.post3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting flash-attn\n",
      "  Downloading flash_attn-2.8.3.tar.gz (8.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting einops\n",
      "  Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 KB\u001b[0m \u001b[31m221.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash-attn) (2.6.0+cu124)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.4.127)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (1.13.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.19.1)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (0.6.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.4.127)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (4.14.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.4.127)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.4.127)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.3)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2.21.5)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.4.127)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->flash-attn) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash-attn) (3.0.2)\n",
      "Building wheels for collected packages: flash-attn\n",
      "  Building wheel for flash-attn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for flash-attn: filename=flash_attn-2.8.3-cp310-cp310-linux_x86_64.whl size=256007522 sha256=1c8d2fb083edea3647688fcd4bb21d4641eb01f50359d8fa6200ecd093ba1c54\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-4v4uzcjd/wheels/f5/05/1e/a6726e9eee2e7ee6151dbfed113e89d220dd3964ba617ab32d\n",
      "Successfully built flash-attn\n",
      "Installing collected packages: einops, flash-attn\n",
      "Successfully installed einops-0.8.1 flash-attn-2.8.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --no-cache-dir torch==2.6.0+cu124 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
    "!pip install transformers>=4.46.0\n",
    "!pip install datasets\n",
    "!pip install unsloth[colab-new]@git+https://github.com/unslothai/unsloth.git\n",
    "!pip install xformers --no-cache-dir   --index-url https://download.pytorch.org/whl/cu124\n",
    "!pip install flash-attn --no-build-isolation --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c268d6f8-7757-49d0-be33-8047b84bc1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "HF_TOKEN = \"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\"\n",
    "login(HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9e0314b-6a69-44e4-8421-5c25163cded7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/main/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d58a162c190e4f12873c5347b9309fa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 26 files:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d6f6f19daf43c4ba255c33c81f0c25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LICENSE:   0%|          | 0.00/11.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e52df1c1c12b40f2a70b23ad7dd1cfbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/15.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72bee42bf5b14764acdb8d2b90da0493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "deid_png.part04:   0%|          | 0.00/15.5G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714ed7524b29486888f6735c2bdf6efb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "deid_png.part03:   0%|          | 0.00/15.5G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e1ff0c882d444099cd1c5a8b99cde1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "deid_png.part02:   0%|          | 0.00/15.5G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70551b2b57f64216a2c496856fec0bdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/3.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89855b6c3f224ad3b21dcab2403e5635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "deid_png.part01:   0%|          | 0.00/15.5G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7901ee5152d040ba8cb79f0068fa5ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "deid_png.part00:   0%|          | 0.00/15.5G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f68bcb625aa491182744eff9e90b24a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "deid_png.part05:   0%|          | 0.00/15.5G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a0b2dcfca394f739124a8899eccf14d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "deid_png.part06:   0%|          | 0.00/15.5G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "780c75ee682e4fccaf28a7f0c7c18805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "deid_png.part07:   0%|          | 0.00/15.5G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9502cbcadce45d788087670607d2fb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "deid_png.part08:   0%|          | 0.00/15.5G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f95800481a41d896bcd5cd7e73ec68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "deid_png.part09:   0%|          | 0.00/15.5G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82b5e74c7cc9417eb0cfb93e99ebfb37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "example/GRDN4SZYTXK18ZTE/GRDNB6085XC789C(…):   0%|          | 0.00/351k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97891bad3fe045f8a1c2e6333b655a4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "example/GRDN4SZYTXK18ZTE/GRDNB6085XC789C(…):   0%|          | 0.00/367k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc7e7e9708cd4066ae1248882f66cd49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "example/GRDN4SZYTXK18ZTE/GRDNXJ9IBYKTA6Z(…):   0%|          | 0.00/212k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8817688d835749a69486f8270829536a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "example/GRDN4SZYTXK18ZTE/GRDNZPKQWDKJ5M9(…):   0%|          | 0.00/202k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3736c1e164154009a4041b10f580b601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test_metadata.csv:   0%|          | 0.00/5.82M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba59f3cbebd5432fb63c008c69588bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "metadata/test_metadata.json:   0%|          | 0.00/17.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37836abed68e4798880d0f062f5369e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "metadata/test_metadata_view_position.jso(…):   0%|          | 0.00/19.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a559a51d2c414134b33b6fbfab84e7a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "metadata/train_metadata.json:   0%|          | 0.00/248M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37eaa2687ca4ab68714303da34e5b7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "metadata/train_metadata.csv:   0%|          | 0.00/81.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31fba81f11ad4dbda7aa65a51a9fe700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "metadata/train_metadata_view_position.js(…):   0%|          | 0.00/249M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d30a226faf54a03b9a55397601f5185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "valid_metadata.csv:   0%|          | 0.00/5.76M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8484a499bbd4c2db4793dc917930051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "metadata/valid_metadata.json:   0%|          | 0.00/17.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50b9f450daa44cbbabd2e01502bf3cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "metadata/valid_metadata_view_position.js(…):   0%|          | 0.00/19.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2220b7ddb80e4dbc973d22e62557bf9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e2bc2c4fa2458691893f460914be2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/2.65k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59c228a2ec0a4adb84a4e5fd848dcc95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "metadata/valid_vqa_data.json:   0%|          | 0.00/124M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "013409eb12c64727aac9f9f6b9ad4b85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LICENSE:   0%|          | 0.00/11.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f5284cbd7f243e8bef3d17fa84c168d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "metadata/train_vqa_data.json:   0%|          | 0.00/1.76G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05727115719147f7b9ca6256de940974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "metadata/test_vqa_data.json:   0%|          | 0.00/125M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6be77f3018fc435c815633b7c7dd8bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/15.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%cd /home/\n",
    "from huggingface_hub import snapshot_download, hf_hub_download\n",
    "from datasets import Dataset\n",
    "\n",
    "REXVQA_REPO = \"rajpurkarlab/ReXVQA\"\n",
    "REXGRAD_REPO = \"rajpurkarlab/ReXGradient-160K\"\n",
    "\n",
    "\n",
    "meta_path = snapshot_download(repo_id=REXGRAD_REPO, repo_type=\"dataset\")\n",
    "\n",
    "!cat {meta_path}/deid_png.part* > /home/deid_png.tar\n",
    "!tar -xf /home/deid_png.tar\n",
    "meta_path = snapshot_download(repo_id=REXVQA_REPO, repo_type=\"dataset\")\n",
    "!mkdir /home/QA_json/\n",
    "!cp  {meta_path}/metadata/test_vqa_data.json  /home/QA_json/\n",
    "!cp  {meta_path}/metadata/train_vqa_data.json  /home/QA_json/\n",
    "!cp  {meta_path}/metadata/valid_vqa_data.json  /home/QA_json/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c56612b-860c-4330-a0ab-912be93a9589",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, json, random\n",
    "from typing import Dict, List, Iterable, Union, Optional\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from datasets import IterableDataset\n",
    "\n",
    "def load_items_once(json_path: str) -> List[Dict]:\n",
    "    \"\"\"Load and normalize one time; return a list of records (dicts).\"\"\"\n",
    "    with open(json_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    items = list(data.values()) if isinstance(data, dict) else list(data)\n",
    "    return items\n",
    "# =======================\n",
    "# Config / Constants\n",
    "# =======================\n",
    "_OPTION_LETTERS = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"]\n",
    "\n",
    "REASONING_START = \"<start_working_out>\"\n",
    "REASONING_END   = \"<end_working_out>\"\n",
    "SOLUTION_START  = \"<SOLUTION>\"\n",
    "SOLUTION_END    = \"</SOLUTION>\"\n",
    "\n",
    "# Probability of adding demographics/context and body/view into the prompt per split.\n",
    "# For TEST we always add them (1.0 as requested).\n",
    "PROMPT_META_PROB = {\n",
    "    \"train\": 0.1,   \n",
    "    \"val\":   0.1,\n",
    "    \"test\":  1.0,    # ALWAYS on test split\n",
    "}\n",
    "PROMPT_BODYVIEW_PROB = {\n",
    "    \"train\": 0.30,   # sometimes\n",
    "    \"val\":   0.30,\n",
    "    \"test\":  1.0,    # ALWAYS on test split\n",
    "}\n",
    "\n",
    "MODEL_ID = \"unsloth/medgemma-4b-it\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "TRAIN_JSON = \"/home/QA_json/train_vqa_data.json\"\n",
    "VAL_JSON   = \"/home/QA_json/valid_vqa_data.json\"\n",
    "TEST_JSON  = \"/home/QA_json/test_vqa_data.json\"\n",
    "\n",
    "# Load once per split\n",
    "train_items = load_items_once(TRAIN_JSON)\n",
    "val_items   = load_items_once(VAL_JSON)\n",
    "test_items  = load_items_once(TEST_JSON)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8543c41-bd8d-4e29-bfd4-04f99d82d5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, json, random\n",
    "from typing import Dict, List, Iterable, Union, Optional\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from datasets import IterableDataset\n",
    "\n",
    "\n",
    "# =======================\n",
    "# Small helpers\n",
    "# =======================\n",
    "def _norm(s: Optional[str]) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", (s or \"\")).strip()\n",
    "\n",
    "def _format_options(options: List[str]) -> str:\n",
    "    lines = []\n",
    "    for i, opt in enumerate(options):\n",
    "        letter = _OPTION_LETTERS[i] if i < len(_OPTION_LETTERS) else chr(ord(\"A\") + i)\n",
    "        opt = _norm(opt)\n",
    "        if re.match(r\"^[A-F][\\)\\.\\-:]\\s\", opt, flags=re.IGNORECASE):\n",
    "            lines.append(opt)  # already labeled\n",
    "        else:\n",
    "            lines.append(f\"{letter}) {opt}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def _safe_open_as_rgb(img_path: str) -> Optional[Image.Image]:\n",
    "    \"\"\"Open image robustly; fix bit-depth; return RGB PIL.Image or None on failure.\"\"\"\n",
    "    try:\n",
    "        im = Image.open(img_path)\n",
    "        im.load()  # force read\n",
    "        arr = np.array(im)\n",
    "\n",
    "        # 16-bit -> keep high 8 bits\n",
    "        if arr.dtype == np.uint16:\n",
    "            arr8 = (arr >> 8).astype(np.uint8)\n",
    "            im = Image.fromarray(arr8)\n",
    "        elif im.mode == \"I\":  # 32-bit signed int -> min-max normalize to 0..255\n",
    "            arr = arr.astype(np.int32)\n",
    "            mn, mx = int(arr.min()), int(arr.max())\n",
    "            if mx > mn:\n",
    "                scale = 255.0 / (mx - mn)\n",
    "                arr8 = ((arr - mn) * scale).astype(np.uint8)\n",
    "            else:\n",
    "                arr8 = np.zeros_like(arr, dtype=np.uint8)\n",
    "            im = Image.fromarray(arr8, mode=\"L\")\n",
    "        return im.convert(\"RGB\")\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# =======================\n",
    "# Reasoning & Prompt builders\n",
    "# =======================\n",
    "def _build_reasoning(record: Dict) -> str:\n",
    "    \"\"\"\n",
    "    Your latest choice: reasoning contains ONLY (in order)\n",
    "    - Findings:\n",
    "    - Impression:\n",
    "    (No correct_answer_explanation and never the answer here.)\n",
    "    \"\"\"\n",
    "    findings = _norm(record.get(\"Findings\"))\n",
    "    impression = _norm(record.get(\"Impression\"))\n",
    "\n",
    "    parts = []\n",
    "    if findings:\n",
    "        parts.append(f\"Findings: {findings}\")\n",
    "    if impression:\n",
    "        parts.append(f\"Impression: {impression}\")\n",
    "    return \"\\n\".join(parts).strip()\n",
    "\n",
    "def _maybe_meta_block(record: Dict, prob: float) -> str:\n",
    "    \"\"\"Demographics/context block with probability `prob` (always for test).\"\"\"\n",
    "    if random.random() >= prob:\n",
    "        return \"\"\n",
    "    patient_sex  = record.get(\"PatientSex\")\n",
    "    patient_age  = record.get(\"PatientAge\")\n",
    "    ethnic_group = record.get(\"EthnicGroup\")\n",
    "    weight       = record.get(\"PatientWeight\")\n",
    "    size         = record.get(\"PatientSize\")\n",
    "    indication   = record.get(\"Indication\")\n",
    "    comparison   = record.get(\"Comparison\")\n",
    "\n",
    "    lines = []\n",
    "    if patient_sex: lines.append(f\"PatientSex: {patient_sex}\")\n",
    "    if patient_age: lines.append(f\"PatientAge: {patient_age}\")\n",
    "    if ethnic_group: lines.append(f\"EthnicGroup: {ethnic_group}\")\n",
    "    try:\n",
    "        if weight is not None and weight == weight:\n",
    "            lines.append(f\"PatientWeight: {weight}\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        if size is not None and size == size:\n",
    "            lines.append(f\"PatientSize: {size}\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    if indication: lines.append(f\"Indication: {indication}\")\n",
    "    if comparison: lines.append(f\"Comparison: {comparison}\")\n",
    "\n",
    "    return (\"CONTEXT:\\n\" + \"\\n\".join(lines)) if lines else \"\"\n",
    "\n",
    "def _maybe_body_view_block(body_part_sel, view_sel, prob: float) -> str:\n",
    "    \"\"\"Randomly include ImageBodyPart & ImageViewPosition (always on test).\"\"\"\n",
    "    if random.random() >= prob:\n",
    "        return \"\"\n",
    "    lines = []\n",
    "    if body_part_sel:\n",
    "        if isinstance(body_part_sel, list):\n",
    "            lines.append(f\"ImageBodyPart: {', '.join(body_part_sel)}\")\n",
    "        else:\n",
    "            lines.append(f\"ImageBodyPart: {body_part_sel}\")\n",
    "    if view_sel:\n",
    "        if isinstance(view_sel, list):\n",
    "            lines.append(f\"ImageViewPosition: {', '.join(view_sel)}\")\n",
    "        else:\n",
    "            lines.append(f\"ImageViewPosition: {view_sel}\")\n",
    "    return \"\\n\".join(lines) if lines else \"\"\n",
    "\n",
    "def _test_only_block(record: Dict, split: str) -> str:\n",
    "    if split != \"test\":\n",
    "        return \"\"\n",
    "    cat_ = record.get(\"category\")\n",
    "    cls_ = record.get(\"class\")\n",
    "    lines = []\n",
    "    if cat_:\n",
    "        lines.append(f\"Category: {cat_}\")\n",
    "    if cls_:\n",
    "        lines.append(f\"Class: {cls_}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def _build_instruction(\n",
    "    record: Dict,\n",
    "    split: str,\n",
    "    body_part_sel,\n",
    "    view_sel,\n",
    ") -> str:\n",
    "    question     = _norm(record.get(\"question\"))\n",
    "    options      = record.get(\"options\") or []\n",
    "    options_block = _format_options(options) if options else \"\"\n",
    "\n",
    "    meta_prob     = PROMPT_META_PROB.get(split, 0.0)\n",
    "    bodyview_prob = PROMPT_BODYVIEW_PROB.get(split, 0.0)\n",
    "\n",
    "    meta_block      = _maybe_meta_block(record, meta_prob)\n",
    "    body_view_block = _maybe_body_view_block(body_part_sel, view_sel, bodyview_prob)\n",
    "    test_block      = _test_only_block(record, split)\n",
    "\n",
    "    chunks = []\n",
    "    if test_block:\n",
    "        chunks.append(test_block)\n",
    "    if question:\n",
    "        chunks.append(question)\n",
    "    if options_block:\n",
    "        chunks.append(\"OPTIONS:\\n\" + options_block)\n",
    "    if meta_block:\n",
    "        chunks.append(meta_block)\n",
    "    if body_view_block:\n",
    "        chunks.append(body_view_block)\n",
    "\n",
    "    return \"\\n\\n\".join([c for c in chunks if c]).strip()\n",
    "\n",
    "# =======================\n",
    "# Image + metadata selection (synced)\n",
    "# =======================\n",
    "def _select_image_and_meta(item: Dict) -> (Optional[str], Optional[Union[str, List[str]]], Optional[Union[str, List[str]]]):\n",
    "    \"\"\"\n",
    "    Choose one image path. If ImagePath, ImageBodyPart, ImageViewPosition are lists,\n",
    "    pick a single random index and return matched body/view for the same index.\n",
    "    Maps '../' -> '/home/'.\n",
    "    \"\"\"\n",
    "    raw_image_paths = item.get(\"ImagePath\")\n",
    "    body_parts_list = item.get(\"ImageBodyPart\")\n",
    "    views_list      = item.get(\"ImageViewPosition\")\n",
    "\n",
    "    body_part_sel = None\n",
    "    view_sel      = None\n",
    "\n",
    "    if isinstance(raw_image_paths, list) and raw_image_paths:\n",
    "        idx = random.randrange(len(raw_image_paths))\n",
    "        raw_image_path = raw_image_paths[idx]\n",
    "        if isinstance(body_parts_list, list) and len(body_parts_list) == len(raw_image_paths):\n",
    "            body_part_sel = body_parts_list[idx]\n",
    "        else:\n",
    "            body_part_sel = body_parts_list\n",
    "        if isinstance(views_list, list) and len(views_list) == len(raw_image_paths):\n",
    "            view_sel = views_list[idx]\n",
    "        else:\n",
    "            view_sel = views_list\n",
    "    else:\n",
    "        raw_image_path = raw_image_paths\n",
    "        body_part_sel  = body_parts_list\n",
    "        view_sel       = views_list\n",
    "\n",
    "    if not isinstance(raw_image_path, str) or not raw_image_path:\n",
    "        return None, body_part_sel, view_sel\n",
    "\n",
    "    img_path = raw_image_path.replace(\"../\", \"/home/\")\n",
    "    return img_path, body_part_sel, view_sel\n",
    "\n",
    "# =======================\n",
    "# Dataset factory\n",
    "# =======================\n",
    "def create_iterable_dataset_from_items(\n",
    "    items: List[Dict],\n",
    "    split: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    Build an IterableDataset from preloaded items.\n",
    "    - No JSON re-read per iteration.\n",
    "    - Reasoning: Findings -> Impression (no answer here).\n",
    "    - Solution: ONLY 'correct_answer' (letter or text).\n",
    "    - Prompt:\n",
    "        * Train/Val: demographics & body/view appear with small probability.\n",
    "        * Test: ALWAYS include demographics & body/view + Category/Class lines.\n",
    "    - Yields a dict with {messages, split, category, class, correct_answer}.\n",
    "    \"\"\"\n",
    "    def generator() -> Iterable[Dict]:\n",
    "        processed = 0\n",
    "        for item in items:\n",
    "            # Pick image and synchronized body/view\n",
    "            img_path, body_part_sel, view_sel = _select_image_and_meta(item)\n",
    "            if not img_path or not os.path.exists(img_path):\n",
    "                continue\n",
    "\n",
    "            img = _safe_open_as_rgb(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "\n",
    "            instruction = _build_instruction(item, split, body_part_sel, view_sel)\n",
    "            reasoning   = _build_reasoning(item)\n",
    "\n",
    "            # Final answer: ONLY the letter/text in 'correct_answer'\n",
    "            correct_letter = _norm(item.get(\"answer\") or item.get(\"correct_answer\"))\n",
    "            explanation = _norm(\n",
    "                item.get(\"explanation\") or item.get(\"correct_answer_explanation\")\n",
    "            )\n",
    "            \n",
    "            if explanation:\n",
    "                # \"Correct answer: B) Minimal scarring at left base. Explanation: ...\"\n",
    "                correct_answer = f\"{correct_letter} - Explanation: {explanation}\"\n",
    "            else:\n",
    "                # If no explanation, just show the letter\n",
    "                correct_answer = correct_letter\n",
    "                \n",
    "            assistant_response = (\n",
    "                f\"{REASONING_START}\\n{reasoning}\\n{REASONING_END}\\n\\n\"\n",
    "                f\"{SOLUTION_START}\\n{correct_answer}\\n{SOLUTION_END}\"\n",
    "            )\n",
    "\n",
    "            processed += 1\n",
    "            if processed % 1000 == 0:\n",
    "                print(f\"[{split}] Processed {processed} samples...\")\n",
    "\n",
    "            output =  {\n",
    "                \"messages\": [\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\"type\": \"text\", \"text\": instruction},\n",
    "                            {\"type\": \"image\", \"image\": img},\n",
    "                        ],\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"assistant\",\n",
    "                        \"content\": [{\"type\": \"text\", \"text\": assistant_response}],\n",
    "                    },\n",
    "                ],\n",
    "                \"split\": split,\n",
    "                # Expose these always for a stable schema\n",
    "                \"category\": _norm(item.get(\"category\")),\n",
    "                \"class\": _norm(item.get(\"class\")),\n",
    "                \"correct_answer\": correct_answer,\n",
    "                \"image_path\": img_path,\n",
    "                \"study_id\" : item.get(\"study_id\"),\n",
    "                \"correct_letter\" : item.get(\"correct_answer\")# handy for debugging/audits\n",
    "            }\n",
    "            if split == \"test\":\n",
    "                yield output\n",
    "            else:\n",
    "                \n",
    "                yield output[\"messages\"]\n",
    "    return IterableDataset.from_generator(generator)\n",
    "\n",
    "# =======================\n",
    "# Example wiring\n",
    "# =======================\n",
    "# Assuming you already loaded JSON into lists:\n",
    "# train_items, val_items, test_items = ...\n",
    "\n",
    "train_dataset = create_iterable_dataset_from_items(train_items, split=\"train\")\n",
    "val_dataset   = create_iterable_dataset_from_items(val_items,   split=\"val\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8116fae-ec77-4237-bdb5-5ba3a97f2d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': [{'type': 'text', 'text': 'Which of the following findings is absent in the lung fields on this chest X-ray?\\n\\nOPTIONS:\\nA. Focal airspace disease\\nB. Mild peribronchial thickening\\nC. Cardiomegaly\\nD. Pleural effusion\\n\\nImageBodyPart: Chest\\nImageViewPosition: PA'}, {'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=748x747 at 0x7F1F09955B70>}]}, {'role': 'assistant', 'content': [{'type': 'text', 'text': '<start_working_out>\\nFindings: The cardiomediastinal silhouette is unremarkable. Mild peribronchial thickening is noted. There is no evidence of focal airspace disease, pulmonary edema, suspicious pulmonary nodule/mass, pleural effusion, or pneumothorax. No acute bony abnormalities are identified.\\nImpression: Mild peribronchial thickening-likely chronic. No other significant abnormalities.\\n<end_working_out>\\n\\n<SOLUTION>\\nA - Explanation: The chest X-ray does not show any focal airspace disease, making A the correct answer. Mild peribronchial thickening is present, and there is no evidence of cardiomegaly or pleural effusion.\\n</SOLUTION>'}]}]\n"
     ]
    }
   ],
   "source": [
    "sample = next(iter(val_dataset))\n",
    "\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "812023d2-5057-4617-a902-6018a83c0d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'study_id': 'pGRDN02Q0SRMKB0WR_aGRDNFJGQZ0FQLITE_s1.2.826.0.1.3680043.8.498.19344862994025691882643805242235663134',\n",
       " 'category': 'Lung and Pleural Opacity',\n",
       " 'class': 'Identifying Findings',\n",
       " 'subcategory': 'Airspace Opacity',\n",
       " 'task_name': 'Negation Assessment',\n",
       " 'question': 'What is the status of the lung fields on this chest X-ray?',\n",
       " 'options': ['A. Presence of acute infiltrate',\n",
       "  'B. Presence of pleural effusion',\n",
       "  'C. No acute infiltrate or pleural effusion',\n",
       "  'D. Presence of pulmonary edema'],\n",
       " 'correct_answer': 'C',\n",
       " 'correct_answer_explanation': 'The chest X-ray does not show any acute infiltrate or pleural effusion, indicating clear lung fields. The correct answer is C.',\n",
       " 'validation_code': 0,\n",
       " 'reason': \"Question contains 'status' keyword\",\n",
       " 'PatientID': 'GRDN02Q0SRMKB0WR',\n",
       " 'AccessionNumber': 'GRDNFJGQZ0FQLITE',\n",
       " 'StudyInstanceUid': '1.2.826.0.1.3680043.8.498.19344862994025691882643805242235663134',\n",
       " 'InstitutionName': 'thryothor-495511-DSL34',\n",
       " 'Manufacturer': \"['SIEMENS']\",\n",
       " 'PatientSex': 'F',\n",
       " 'PatientAge': '058Y',\n",
       " 'EthnicGroup': None,\n",
       " 'PatientWeight': 78.4714852,\n",
       " 'PatientSize': nan,\n",
       " 'StudyDate': 20101110,\n",
       " 'StudyDescription': 'DG CHEST 1V',\n",
       " 'Indication': 'Trauma post MVC',\n",
       " 'Comparison': 'None',\n",
       " 'Findings': 'Cardiomediastinal silhouette is unremarkable. Surgical clip noted left axilla. No acute infiltrate or pleural effusion. No pulmonary edema. No diagnostic pneumothorax.',\n",
       " 'Impression': 'No active disease.',\n",
       " 'ImagePath': ['../deid_png/GRDN02Q0SRMKB0WR/GRDNFJGQZ0FQLITE/studies/1.2.826.0.1.3680043.8.498.19344862994025691882643805242235663134/series/1.2.826.0.1.3680043.8.498.53187597327934495903568856078240920884/instances/1.2.826.0.1.3680043.8.498.38066650272049436950331194578163251791.png'],\n",
       " 'ImageModality': [''],\n",
       " 'ImageShape': [''],\n",
       " 'ImageBodyPart': [''],\n",
       " 'ImageViewPosition': ['UNKNOWN']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_items[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1830984-c791-46de-8764-e2586e251d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.8.6: Fast Gemma3 patching. Transformers: 4.55.2.\n",
      "   \\\\   /|    NVIDIA A40. Num GPUs = 1. Max memory: 44.352 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: Making `base_model.model.model.vision_tower.vision_model` require gradients\n",
      "Model loaded successfully with LoRA adapters\n"
     ]
    }
   ],
   "source": [
    "from unsloth.trainer import UnslothVisionDataCollator\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "import torch \n",
    "from unsloth import FastVisionModel \n",
    "from transformers import TextStreamer \n",
    "from trl import SFTTrainer \n",
    "from transformers import TrainingArguments \n",
    "from unsloth import is_bfloat16_supported \n",
    "\n",
    "model, processor = FastVisionModel.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    load_in_4bit = True, # Use 4bit to reduce memory use. False for 16bit LoRA.\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for long context\n",
    ")\n",
    "# Add LoRA adapters\n",
    "model = FastVisionModel.get_peft_model(\n",
    "    model,\n",
    "    finetune_vision_layers     = True, # False if not finetuning vision layers\n",
    "    finetune_language_layers   = True, # False if not finetuning language layers\n",
    "    finetune_attention_modules = True, # False if not finetuning attention layers\n",
    "    finetune_mlp_modules       = True, # False if not finetuning MLP layers\n",
    "\n",
    "    r = 16,                           # The larger, the higher the accuracy, but might overfit\n",
    "    lora_alpha = 16,                  # Recommended alpha == r at least\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,               # We support rank stabilized LoRA\n",
    "    loftq_config = None,               # And LoftQ\n",
    "    target_modules = \"all-linear\",    # Optional now! Can specify a list if needed\n",
    "    modules_to_save=[\n",
    "        \"lm_head\",\n",
    "        \"embed_tokens\",\n",
    "    ],\n",
    ")\n",
    "print(\"Model loaded successfully with LoRA adapters\")\n",
    "\n",
    "FastVisionModel.for_training(model) # Enable for training!\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    processing_class=processor.tokenizer,\n",
    "    data_collator=UnslothVisionDataCollator(model, processor),\n",
    "    args = SFTConfig(\n",
    "        per_device_train_batch_size = 4,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        gradient_checkpointing = True,\n",
    "\n",
    "        # use reentrant checkpointing\n",
    "        gradient_checkpointing_kwargs = {\"use_reentrant\": False},\n",
    "        max_grad_norm = 0.3,              # max gradient norm based on QLoRA paper\n",
    "        warmup_ratio = 0.03,\n",
    "        max_steps = 100,\n",
    "        #num_train_epochs = 2,          # Set this instead of max_steps for full training runs\n",
    "        learning_rate = 2e-4,\n",
    "        logging_steps = 1,\n",
    "        save_strategy=\"steps\",\n",
    "        optim = \"adamw_torch_fused\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"cosine\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"none\",             # For Weights and Biases\n",
    "\n",
    "        # You MUST put the below items for vision finetuning:\n",
    "        remove_unused_columns = False,\n",
    "        dataset_text_field = \"\",\n",
    "        dataset_kwargs = {\"skip_prepare_dataset\": True},\n",
    "        max_length = 2048,\n",
    "    )\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f846f89-abe3-4c0e-a121-290be8460659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting SFT training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 1,600 | Num Epochs = 9,223,372,036,854,775,807 | Total steps = 100\n",
      "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 4 x 1) = 16\n",
      " \"-____-\"     Trainable parameters = 38,497,792 of 4,338,577,264 (0.89% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 15:58, Epoch 1/9223372036854775807]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.933100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.010900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.936400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.731100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.308400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.202200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.989900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.840300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.868100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.574600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.371400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.312600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.232300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.024300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.953500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.962100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.863000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.836400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.831200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.830400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.782600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.634600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.642700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.731100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.584800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.684900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.938000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.764400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.053100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.846000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.802400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.077000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.861700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.903500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.766500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.581400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.830200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.684300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.766700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.603500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.700100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.618600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.592300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.441700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.715300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.578200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.855000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.817600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.760200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.684300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.586300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.588400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.652900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.729900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.913300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.549100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.562100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.625900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.860500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.736400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.778200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.542700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.484400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.968100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.577600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.558200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.982500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.875600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.643800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.772300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.976000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.466800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.908200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.642800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.504000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.625500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.425300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.666900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.441700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.607900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.722200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.869100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.891100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.702700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.809100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.886500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.748100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.575800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.696400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>1.013700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.835000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.821200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.754600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.779100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.681200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.621300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Processed 1000 samples...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Starting SFT training...\")\n",
    "trainer_stats = trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1958f29-54e8-4022-b722-0c4f656e3b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start_working_out>\n",
      "Findings: The lung volumes are normal. There is stable bibasilar scarring. Stable no pulmonary edema or pneumothorax. The heart size remains within normal limits. There is no lymphadenopathy.\n",
      "Impression: Stable bibasilar scarring.\n",
      "<end_working_out>\n",
      "\n",
      "<SOLUTION>\n",
      "C - Explanation: The chest X-ray report indicates that the bibasilar scarring is stable, meaning it has not changed since the previous comparison study. Therefore, the correct answer is C.\n",
      "</SOLUTION><end_of_turn>\n"
     ]
    }
   ],
   "source": [
    "FastVisionModel.for_inference(model)  # Enable for inference!\n",
    "test_dataset  = create_iterable_dataset_from_items(test_items[:100],  split=\"test\")\n",
    "\n",
    "data = next(iter(test_dataset))\n",
    "\n",
    "\n",
    "image = data[\"messages\"][0][\"content\"][1].pop(\"image\")\n",
    "messages = [data[\"messages\"][0]]\n",
    "class_data= data[\"class\"]\n",
    "category= data[\"category\"]\n",
    "\n",
    "correct_answer= data[\"correct_answer\"]\n",
    "\n",
    "\n",
    "input_text = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "inputs = processor(\n",
    "    image,\n",
    "    input_text,\n",
    "    add_special_tokens=False,\n",
    "    return_tensors=\"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "\n",
    "text_streamer = TextStreamer(processor.tokenizer, skip_prompt=True)\n",
    "_ = model.generate(**inputs, streamer=text_streamer, max_new_tokens = 512,\n",
    "                   use_cache=True, temperature = 1.0, top_p = 0.95, top_k = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9a7df00-802c-4203-8983-dace4b2944d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': 'Category: Lung and Pleural Opacity\\nClass: Identifying Findings\\n\\nWhat is the status of the bibasilar scarring observed on this chest X-ray?\\n\\nOPTIONS:\\nA. New bibasilar scarring\\nB. Worsening bibasilar scarring\\nC. Stable bibasilar scarring\\nD. Resolving bibasilar scarring\\n\\nCONTEXT:\\nPatientSex: F\\nPatientAge: 072Y\\nIndication: Preoperative respiratory examination for abdominal aortic aneurysm surgery.\\nComparison: Comparison: Abdominal CTA 07/28/2020.\\n\\nImageBodyPart: Chest\\nImageViewPosition: LATERAL'},\n",
       "    {'type': 'image'}]},\n",
       "  {'role': 'assistant',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': '<start_working_out>\\nFindings: There is cardiac enlargement and mild aortic ectasia status post CABG. Bibasilar scarring appears unchanged. There is no edema or confluent airspace opacity. There is no pleural effusion. No acute osseous findings are identified.\\nImpression: Stable bibasilar scarring. No acute cardiopulmonary process.\\n<end_working_out>\\n\\n<SOLUTION>\\nC - Explanation: The chest X-ray shows stable bibasilar scarring, indicating no change from previous imaging. Options A, B, and D are incorrect as there is no new, worsening, or resolving scarring.\\n</SOLUTION>'}]}],\n",
       " 'split': 'test',\n",
       " 'category': 'Lung and Pleural Opacity',\n",
       " 'class': 'Identifying Findings',\n",
       " 'correct_answer': 'C - Explanation: The chest X-ray shows stable bibasilar scarring, indicating no change from previous imaging. Options A, B, and D are incorrect as there is no new, worsening, or resolving scarring.',\n",
       " 'image_path': '/home/deid_png/GRDN002XFK7K18YN/GRDNXZESKHNCBYGB/studies/1.2.826.0.1.3680043.8.498.22735358327567601089576851015768204060/series/1.2.826.0.1.3680043.8.498.88412707246131132701499297126463884606/instances/1.2.826.0.1.3680043.8.498.54072220713434730573937547661072486161.png',\n",
       " 'study_id': 'pGRDN002XFK7K18YN_aGRDNXZESKHNCBYGB_s1.2.826.0.1.3680043.8.498.22735358327567601089576851015768204060',\n",
       " 'correct_letter': 'C'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8818e392-e6a2-470f-b646-b4e0a260f464",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (2.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c75abd15ae42b79f82ea4a9c37c599",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error - Saving Excel\n",
      "Overall: {'correct': 83, 'total': 100, 'accuracy': 0.83}\n",
      "Per-category: {'Airway': {'correct': 2, 'total': 2, 'accuracy': 1.0}, 'Aorta': {'correct': 4, 'total': 4, 'accuracy': 1.0}, 'Bone': {'correct': 1, 'total': 2, 'accuracy': 0.5}, 'Bony Structures': {'correct': 1, 'total': 1, 'accuracy': 1.0}, 'Diaphragm': {'correct': 1, 'total': 1, 'accuracy': 1.0}, 'Heart': {'correct': 11, 'total': 14, 'accuracy': 0.7857142857142857}, 'Implanted Devices': {'correct': 1, 'total': 1, 'accuracy': 1.0}, 'Infectious Disease': {'correct': 5, 'total': 5, 'accuracy': 1.0}, 'Lung Volume': {'correct': 2, 'total': 2, 'accuracy': 1.0}, 'Lung and Pleural Opacity': {'correct': 22, 'total': 27, 'accuracy': 0.8148148148148148}, 'Mediastinum': {'correct': 1, 'total': 1, 'accuracy': 1.0}, 'Miscellaneous Bone Abnormality': {'correct': 1, 'total': 1, 'accuracy': 1.0}, 'Negation': {'correct': 15, 'total': 17, 'accuracy': 0.8823529411764706}, 'Other Pulmonary Diagnosis': {'correct': 0, 'total': 2, 'accuracy': 0.0}, 'Pulmonary Vascularity': {'correct': 1, 'total': 1, 'accuracy': 1.0}, 'Quality of Exams': {'correct': 3, 'total': 6, 'accuracy': 0.5}, 'Rib': {'correct': 4, 'total': 4, 'accuracy': 1.0}, 'Skeletal Structures': {'correct': 2, 'total': 2, 'accuracy': 1.0}, 'Spine': {'correct': 4, 'total': 4, 'accuracy': 1.0}, 'Tubes and Lines': {'correct': 2, 'total': 3, 'accuracy': 0.6666666666666666}}\n",
      "Per-class: {'Identifying Findings': {'correct': 63, 'total': 76, 'accuracy': 0.8289473684210527}, 'Suggesting Clinical Diagnosis': {'correct': 20, 'total': 24, 'accuracy': 0.8333333333333334}}\n",
      "CSV: eval_results_20250816_181740.csv\n",
      "XLSX: None\n",
      "Unparsed/errored samples: 0\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl\n",
    "\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "from typing import Dict, Any, Optional, List\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Optional: Excel export\n",
    "try:\n",
    "    import pandas as pd\n",
    "except Exception:\n",
    "    pd = None\n",
    "import csv\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "LETTER_SET = set(list(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"))  # supports up to 26 options\n",
    "\n",
    "\n",
    "def _extract_solution_block(text: str) -> str:\n",
    "    \"\"\"Return the content inside <SOLUTION>...</SOLUTION> if present; else full text.\"\"\"\n",
    "    m = re.search(r\"<SOLUTION>(.*)</SOLUTION>\", text, flags=re.DOTALL | re.IGNORECASE)\n",
    "    return m.group(1) if m else text\n",
    "\n",
    "\n",
    "def _first_letter_candidate(s: str) -> Optional[str]:\n",
    "    \"\"\"Find the first plausible option letter in a string, including newline-start cases.\"\"\"\n",
    "    patterns = [\n",
    "        r\"\\boption\\s*([A-Z])\\b\",\n",
    "        r\"\\banswer\\s*[:\\-]?\\s*([A-Z])\\b\",\n",
    "        r\"^\\s*([A-Z])\\s*[\\)\\.\\-:]\\s\",   # \"C) \", \"C. \", \"C- \", \"C: \"\n",
    "        r\"^\\s*([A-Z])\\s*-\\s\",            # \"C -\"\n",
    "        r\"^\\s*([A-Z])\\s*$\",              # standalone letter on its own line\n",
    "        r\"\\n\\s*([A-Z])\\s*[\\)\\.\\-:]\\s\",   # \"\\nC) ...\" or \"\\nC: ...\"\n",
    "        r\"\\n\\s*([A-Z])\\s*$\",             # \"\\nC\\n\"\n",
    "    ]\n",
    "    for pat in patterns:\n",
    "        m = re.search(pat, s, flags=re.IGNORECASE | re.MULTILINE)\n",
    "        if m:\n",
    "            letter = m.group(1).upper()\n",
    "            if letter in LETTER_SET:\n",
    "                return letter\n",
    "    # fallback: first standalone capital A–Z\n",
    "    m = re.search(r\"\\b([A-Z])\\b\", s)\n",
    "    if m:\n",
    "        letter = m.group(1).upper()\n",
    "        if letter in LETTER_SET:\n",
    "            return letter\n",
    "    return None\n",
    "\n",
    "\n",
    "def parse_predicted_letter(generated_text: str) -> Optional[str]:\n",
    "    \"\"\"Prefer <SOLUTION>...</SOLUTION>, else scan whole text.\"\"\"\n",
    "    block = _extract_solution_block(generated_text)\n",
    "    letter = _first_letter_candidate(block)\n",
    "    if letter is None and block != generated_text:\n",
    "        letter = _first_letter_candidate(generated_text)\n",
    "    return letter\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def evaluate_mcq(\n",
    "    model,\n",
    "    processor,\n",
    "    test_dataset,\n",
    "    device: str = \"cuda\",\n",
    "    max_new_tokens: int = 512,\n",
    "    temperature: float = 1.0,\n",
    "    top_p: float = 0.95,\n",
    "    top_k: int = 64,\n",
    "    limit: Optional[int] = None,\n",
    "    show_progress: bool = True,\n",
    "    # --- export options ---\n",
    "    export_path_base: str = \"eval_results\",\n",
    "    save_csv: bool = True,\n",
    "    save_xlsx: bool = True,   # requires pandas\n",
    "    include_pred_text_snippet: bool = True,\n",
    "    pred_text_snippet_len: int = 300,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Evaluate MCQ and export a table with columns:\n",
    "      study_id, correct_answer, predicted_answer, is_correct, category, class, pred_text_snippet\n",
    "\n",
    "    Returns a dict with:\n",
    "      - overall / by_category / by_class accuracies\n",
    "      - table_path_csv / table_path_xlsx (if written)\n",
    "      - errors list\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    overall = Counter()\n",
    "    by_category_counts = defaultdict(Counter)\n",
    "    by_class_counts = defaultdict(Counter)\n",
    "    errors: List[Dict[str, Any]] = []\n",
    "\n",
    "    # rows for export\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "\n",
    "    iterator = iter(test_dataset)\n",
    "    n = 0\n",
    "\n",
    "    pbar = tqdm(total=limit if limit is not None else None, disable=not show_progress)\n",
    "\n",
    "    while True:\n",
    "        if limit is not None and n >= limit:\n",
    "            break\n",
    "        try:\n",
    "            data = next(iterator)\n",
    "        except StopIteration:\n",
    "            break\n",
    "\n",
    "        # Unpack fields\n",
    "        try:\n",
    "            image = data[\"messages\"][0][\"content\"][1].get(\"image\", None)\n",
    "            _ = data[\"messages\"][0][\"content\"][1].pop(\"image\", None)\n",
    "            messages = [data[\"messages\"][0]]\n",
    "            # optional/unused, but present in your structure:\n",
    "            # answer = [data[\"messages\"][1]]\n",
    "\n",
    "            study_id = str(data.get(\"study_id\", n))\n",
    "            correct_letter = str(data[\"correct_letter\"]).strip().upper()\n",
    "            category = str(data.get(\"category\", \"UNKNOWN\"))\n",
    "            clazz = str(data.get(\"class\", \"UNKNOWN\"))\n",
    "        except Exception as e:\n",
    "            errors.append({\"index\": n, \"error\": f\"bad sample structure: {e}\"})\n",
    "            n += 1\n",
    "            pbar.update(1)\n",
    "            continue\n",
    "\n",
    "        # Build inputs\n",
    "        try:\n",
    "            input_text = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "            inputs = processor(\n",
    "                image,\n",
    "                input_text,\n",
    "                add_special_tokens=False,\n",
    "                return_tensors=\"pt\",\n",
    "            ).to(device)\n",
    "        except Exception as e:\n",
    "            errors.append({\"index\": n, \"error\": f\"processor/build failed: {e}\"})\n",
    "            n += 1\n",
    "            pbar.update(1)\n",
    "            continue\n",
    "\n",
    "        # Generate\n",
    "        try:\n",
    "            gen_out = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                use_cache=True,\n",
    "                temperature=temperature,\n",
    "                top_p=top_p,\n",
    "                top_k=top_k,\n",
    "            )\n",
    "            pred_text = processor.tokenizer.decode(gen_out[0], skip_special_tokens=True)\n",
    "        except Exception as e:\n",
    "            errors.append({\"index\": n, \"error\": f\"generate failed: {e}\"})\n",
    "            n += 1\n",
    "            pbar.update(1)\n",
    "            continue\n",
    "\n",
    "        # Parse prediction\n",
    "        pred_letter = parse_predicted_letter(pred_text)\n",
    "\n",
    "        # Update counters\n",
    "        overall[\"total\"] += 1\n",
    "        by_category_counts[category][\"total\"] += 1\n",
    "        by_class_counts[clazz][\"total\"] += 1\n",
    "\n",
    "        is_correct = False\n",
    "        if pred_letter is None:\n",
    "            errors.append({\"index\": n, \"error\": \"parse_failed\", \"text\": pred_text})\n",
    "        else:\n",
    "            if pred_letter == correct_letter:\n",
    "                is_correct = True\n",
    "                overall[\"correct\"] += 1\n",
    "                by_category_counts[category][\"correct\"] += 1\n",
    "                by_class_counts[clazz][\"correct\"] += 1\n",
    "\n",
    "        # Add export row\n",
    "        row = {\n",
    "            \"study_id\": study_id,\n",
    "            \"correct_answer\": correct_letter,\n",
    "            \"predicted_answer\": pred_letter if pred_letter is not None else \"\",\n",
    "            \"is_correct\": bool(is_correct),\n",
    "            \"category\": category,\n",
    "            \"class\": clazz,\n",
    "        }\n",
    "        if include_pred_text_snippet:\n",
    "            row[\"pred_text_snippet\"] = (pred_text[:pred_text_snippet_len].replace(\"\\n\", \"\\\\n\")\n",
    "                                        if isinstance(pred_text, str) else \"\")\n",
    "        rows.append(row)\n",
    "\n",
    "        n += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    def _with_acc(c: Counter) -> Dict[str, float]:\n",
    "        total = int(c.get(\"total\", 0))\n",
    "        correct = int(c.get(\"correct\", 0))\n",
    "        acc = (correct / total) if total > 0 else 0.0\n",
    "        return {\"correct\": correct, \"total\": total, \"accuracy\": acc}\n",
    "\n",
    "    results = {\n",
    "        \"overall\": _with_acc(overall),\n",
    "        \"by_category\": {k: _with_acc(v) for k, v in sorted(by_category_counts.items())},\n",
    "        \"by_class\": {k: _with_acc(v) for k, v in sorted(by_class_counts.items())},\n",
    "        \"errors\": errors,\n",
    "    }\n",
    "\n",
    "    # ---- Write table(s) ----\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    base = f\"{export_path_base}_{timestamp}\"\n",
    "    csv_path = f\"{base}.csv\"\n",
    "    xlsx_path = f\"{base}.xlsx\"\n",
    "\n",
    "    # CSV: always available\n",
    "\n",
    "    try:\n",
    "        if save_csv:\n",
    "            os.makedirs(os.path.dirname(csv_path) or \".\", exist_ok=True)\n",
    "            with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "                writer = csv.DictWriter(f, fieldnames=list(rows[0].keys()) if rows else\n",
    "                                        [\"study_id\",\"correct_answer\",\"predicted_answer\",\"is_correct\",\"category\",\"class\",\"pred_text_snippet\"])\n",
    "                writer.writeheader()\n",
    "                for r in rows:\n",
    "                    writer.writerow(r)\n",
    "            results[\"table_path_csv\"] = csv_path\n",
    "    except:\n",
    "        print(\"Error - Saving CSV\")\n",
    "        pass\n",
    "\n",
    "\n",
    "    try:\n",
    "\n",
    "        # XLSX: needs pandas\n",
    "        if save_xlsx:\n",
    "            if pd is None:\n",
    "                results[\"table_path_xlsx\"] = None\n",
    "                results[\"xlsx_warning\"] = \"pandas not available; skipped .xlsx export\"\n",
    "            else:\n",
    "                df = pd.DataFrame(rows)\n",
    "                os.makedirs(os.path.dirname(xlsx_path) or \".\", exist_ok=True)\n",
    "                df.to_excel(xlsx_path, index=False)\n",
    "                results[\"table_path_xlsx\"] = xlsx_path\n",
    "    except:\n",
    "        print(\"Error - Saving Excel\")\n",
    "        pass\n",
    "    return results\n",
    "\n",
    "\n",
    "# ---- Example usage ----\n",
    "# FastVisionModel.for_inference(model)\n",
    "results = evaluate_mcq(model, processor, test_dataset, device=\"cuda\", limit=100)\n",
    "print(\"Overall:\", results[\"overall\"])\n",
    "print(\"Per-category:\", results[\"by_category\"])\n",
    "print(\"Per-class:\", results[\"by_class\"])\n",
    "print(\"CSV:\", results.get(\"table_path_csv\"))\n",
    "print(\"XLSX:\", results.get(\"table_path_xlsx\"))\n",
    "print(f\"Unparsed/errored samples: {len(results['errors'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a7cb6d-2e5c-4c60-bb36-535948023259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save locally to 16bit\n",
    "#model.save_pretrained_merged(\"/home/unsloth_finetune\", processor)\n",
    "# Save locally\n",
    "#model.save_pretrained(\"/home/weights\")\n",
    "#processor.save_pretrained(\"/home/weights\")\n",
    "\n",
    "\n",
    "# To export and save to your Hugging Face account\n",
    "model.push_to_hub_merged(\"SerdarHelli/medgemma-4b-it_rexvqa_sft\", processor, token = HF_TOKEN)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
